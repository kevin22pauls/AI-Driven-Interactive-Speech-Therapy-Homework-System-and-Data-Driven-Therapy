# AI-Powered Speech Therapy Homework System

An intelligent speech therapy system for aphasia patients and speech disorders, featuring **phoneme-level analysis** to identify exactly which sounds patients struggle with.

![Research Grade](https://img.shields.io/badge/status-research%20grade-blue)
![Python](https://img.shields.io/badge/python-3.8+-blue)
![License](https://img.shields.io/badge/license-MIT-green)

---

## ğŸ¯ Overview

This system provides **multi-level speech analysis**:
- **Word-level**: WER, speech rate, pause ratio
- **Phoneme-level**: PER, error classification, problematic sounds
- **Semantic-level**: Answer correctness, paraphrasing detection

**Example**: When a patient says "bootle" instead of "bottle", the system identifies:
- PER: 20%
- Error: `AA â†’ UW` substitution at phoneme position 1
- Clinical insight: "Consider vowel discrimination exercises"

---

## âœ¨ Key Features

### ğŸ”¬ Phoneme-Level Analysis (NEW)
- **Phoneme Error Rate (PER)** calculation
- Error type classification: substitutions, deletions, insertions
- **Identifies problematic phonemes** for targeted therapy
- Longitudinal tracking of phoneme improvement
- Clinical insights generation

### ğŸ™ï¸ Speech Recognition
- Faster-Whisper ASR (CPU-optimized)
- Automatic silence detection
- Multi-format audio support (webm, wav, mp3)

### ğŸ“Š Comprehensive Metrics
- Word Error Rate (WER)
- Speech rate (words/minute)
- Pause ratio analysis
- Semantic similarity scoring

### ğŸ§  Semantic Analysis
- Sentence transformer-based evaluation
- Three-tier classification (correct/partial/wrong)
- Paraphrase detection
- Object identification verification

### ğŸ’» User-Friendly Interface
- Browser-based recording
- Real-time feedback
- Color-coded results
- Detailed error visualization

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Docker (optional, for forced alignment)

### Installation

1. **Clone the repository**
```bash
git clone <your-repo-url>
cd "FINAL PROJECT"
```

2. **Install Python dependencies**
```bash
cd backend
pip install -r requirements.txt
```

3. **(Optional) Start Gentle for phoneme timestamps**
```bash
docker-compose up -d gentle
```

4. **Start the backend server**
```bash
cd backend
uvicorn main:app --reload --port 8000
```

5. **Open the frontend**
```
Open backend/frontend/recorder.html in your web browser
```

---

## ğŸ“– Usage

### Basic Workflow

1. **Click "Get Prompt"** â†’ System provides a prompt (e.g., "What is this object?")
2. **Click "Start Recording"** â†’ Speak your answer
3. **Recording auto-stops** after silence (900ms) or 8 seconds
4. **View Results**:
   - Transcript
   - Semantic evaluation (âœ“ correct / âš ï¸ partial / âœ— wrong)
   - **Phoneme Error Rate (PER)**
   - **Problematic phonemes** (e.g., "AA: 2 errors")
   - **Clinical insights** (e.g., "Focus on fricative production")
   - Detailed error table

5. **Continue Session**:
   - "Get Prompt" â†’ Another prompt for same object
   - "New Object" â†’ Switch to different object

---

## ğŸ—ï¸ Architecture

```
Frontend (HTML/JS)
    â†“
FastAPI Backend
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Speech Processing Pipeline     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Whisper ASR                 â”‚
â”‚  2. Word-Level Metrics          â”‚
â”‚  3. Phoneme Analysis â­ NEW     â”‚
â”‚  4. Semantic Evaluation         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
SQLite Database
```

### Key Components

| Component | Description |
|-----------|-------------|
| `speech_processing.py` | Main analysis pipeline |
| `phoneme_analysis.py` | PER calculation & error detection |
| `phoneme_lookup.py` | CMU Dict wrapper (134k words) |
| `forced_alignment.py` | Gentle integration for timestamps |
| `semantic_analysis.py` | Sentence transformer evaluation |

---

## ğŸ“Š API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/session/start` | POST | Start new session |
| `/session/next-prompt` | POST | Get next prompt |
| `/session/change-object` | POST | Switch object |
| `/record` | POST | Upload audio & analyze |

### Example Response

```json
{
  "transcript": "this is a bootle",
  "wer": 0.25,
  "speech_rate": 120.5,
  "semantic_evaluation": {
    "classification": "partial",
    "similarity_score": 0.78
  },
  "phoneme_analysis": {
    "per": 0.20,
    "error_count": 1,
    "errors": [
      {
        "type": "substitution",
        "expected": "AH",
        "actual": "UW",
        "word": "bottle",
        "position": 1
      }
    ],
    "problematic_phonemes": {"AH": 1},
    "clinical_notes": [
      "Moderate phoneme errors detected",
      "Consider vowel discrimination exercises"
    ]
  }
}
```

---

## ğŸ§ª Testing

Run unit tests:

```bash
cd backend
pytest tests/test_phoneme_analysis.py -v
```

**Test Coverage**:
- âœ“ PER calculation (perfect match, substitutions, deletions, insertions)
- âœ“ Phoneme alignment algorithm
- âœ“ CMU Dictionary lookups
- âœ“ Clinical note generation
- âœ“ Error classification

---

## ğŸ“ Project Structure

```
FINAL PROJECT/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                       # FastAPI app
â”‚   â”œâ”€â”€ requirements.txt              # Dependencies
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â””â”€â”€ analysis.py               # API endpoints
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ speech_processing.py      # Main pipeline
â”‚   â”‚   â”œâ”€â”€ phoneme_analysis.py       # â­ Phoneme PER
â”‚   â”‚   â”œâ”€â”€ phoneme_lookup.py         # â­ CMU Dict
â”‚   â”‚   â”œâ”€â”€ forced_alignment.py       # â­ Gentle
â”‚   â”‚   â”œâ”€â”€ semantic_analysis.py      # Transformers
â”‚   â”‚   â””â”€â”€ prompts.py                # Prompt system
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ cmudict-0.7b.txt          # â­ 134k words
â”‚   â”œâ”€â”€ frontend/
â”‚   â”‚   â””â”€â”€ recorder.html             # UI
â”‚   â””â”€â”€ tests/
â”‚       â””â”€â”€ test_phoneme_analysis.py  # â­ Unit tests
â”œâ”€â”€ docker-compose.yml                # â­ Gentle service
â”œâ”€â”€ PROJECT_DOCUMENTATION.txt         # â­ Full docs
â””â”€â”€ README.md                         # This file
```

---

## ğŸ”¬ Research Applications

This system enables:
- **Phoneme-level error tracking** over time
- **Personalized therapy targets** (focus on problematic sounds)
- **Automated homework assessment**
- **Large-scale aphasia research**
- **Outcome measurement** for clinical trials

### Clinical Use Cases
1. **Aphasia rehabilitation** - Track pronunciation improvement
2. **Dysarthria therapy** - Identify motor speech patterns
3. **Speech sound disorders** - Phonological error analysis
4. **Accent modification** - Phoneme-level feedback

---

## ğŸ“š Documentation

- **[PROJECT_DOCUMENTATION.txt](PROJECT_DOCUMENTATION.txt)** - Comprehensive technical documentation
  - Architecture details
  - Algorithm descriptions
  - Database schema
  - Clinical validation guidelines
  - Research considerations

---

## ğŸ› ï¸ Dependencies

**Core Libraries**:
- `fastapi` - Web framework
- `faster-whisper` - ASR model
- `sentence-transformers` - Semantic analysis
- `editdistance` - Phoneme alignment
- `jiwer` - WER calculation
- `sqlalchemy` - Database ORM

**Full list**: See [backend/requirements.txt](backend/requirements.txt)

---

## âš™ï¸ Configuration

### Environment Variables

```bash
# Optional: Custom Gentle URL
export GENTLE_URL=http://localhost:8765

# Optional: Whisper model size
# Edit backend/config.py:
WHISPER_MODEL_SIZE = "small"  # or "tiny", "base"
```

---

## ğŸ” Known Limitations

1. **No patient management** - Single-user interface (add auth for production)
2. **Database saves not yet implemented** - Results returned via API only
3. **Gentle is optional** - Works without forced alignment
4. **English only** - CMU Dict is American English
5. **Not FDA-approved** - Research use only

---

## ğŸš§ Future Enhancements

- [ ] Multi-patient dashboard
- [ ] Progress visualization charts
- [ ] GOP (Goodness of Pronunciation) scores
- [ ] Database persistence implementation
- [ ] Mobile app version
- [ ] Real-time feedback during recording
- [ ] Multi-language support
- [ ] HIPAA compliance features

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸ™ Acknowledgments

This project uses:
- **CMU Pronouncing Dictionary** (CMU Sphinx)
- **Faster-Whisper** (OpenAI Whisper optimized)
- **Gentle Forced Aligner** (lowerquality/gentle)
- **Sentence Transformers** (UKPLab)

---

## ğŸ“§ Contact

For research collaboration or questions:
- GitHub Issues: [Create an issue](issues)
- Email: [your-email@example.com]

---

## ğŸ“Š Citation

If you use this system in your research, please cite:

```bibtex
@software{speech_therapy_system_2025,
  title={AI-Powered Speech Therapy Homework System with Phoneme-Level Analysis},
  author={Your Name},
  year={2025},
  url={https://github.com/yourusername/yourrepo}
}
```

---

## â­ Key Innovation

**This system uniquely provides phoneme-level error analysis**, answering the critical clinical question:

> "The patient said 'bootle' instead of 'bottle' - but **which phoneme** was mispronounced, and **what** should we practice?"

**Answer**: `AA â†’ UW` substitution â†’ Vowel discrimination exercises needed.

---

**Built with â¤ï¸ for speech therapy research**

*Last updated: December 22, 2025*
